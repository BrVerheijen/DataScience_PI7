{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PI7 Onderzoeksrapport\n",
    "#### Dajmen Graus en Bram Verheijen "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selectie/Preperation\n",
    "Voor het verkrijgen van een passende dataset werden meerdere bronnen doorzocht met verzamelingen van verschillende datasets. Deze datasets werden langs de eisen vanuit de opdrachtomschrijving gelegd, waardoor uiteindlijk een dataset werd gekozen die gepast is voor de opdracht. De gekozen dataset heeft alleen één datatype, namelijk getallen. Echter bleek deze dataset zeer geschikt te zijn voor het gebruik met classification en regression. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gekozen Dataset\n",
    "De dataset die uiteindelijk werd gekozen voor deze opdracht, is een dataset over de kwaliteit van verschillende rode wijnen. De kwaliteit wordt bepaald op basis van 11 aspecten:\n",
    "- fixed acidity\n",
    "- volatile acidity\n",
    "- citric acid\n",
    "- residual sugar\n",
    "- chlorides\n",
    "- free sulfur dioxide\n",
    "- total sulfur dioxide\n",
    "- density\n",
    "- pH\n",
    "- sulphates\n",
    "- alcohol\n",
    "\n",
    "Uit deze aspecten komt uiteindelijk de \"quality\" feature. Deze feature legt vast wat de kwaliteit van een specifieke soort rode wijn is. De dataset bestaat uit 1600 records, welke genoeg zullen zijn om te gebruiken voor de train- en testdata. Deze dataset is [hier](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009?resource=download) terug te vinden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports en inlezen data\n",
    "In de onderstaande code is te zien hoe de dataset wordt ingelezen en welke libraries worden gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperatie voor Logistic Regression en Classification\n",
    "In de onderstaande code is te zien hoe een label wordt aangemaakt wat gebruikt kan worden voor classificatie en logistic regression. Dit wordt gedaan door middel van de \"quality\" feature te doorlezen en sorteren op hoge kwaliteit en lage kwaliteit. Dit wordt opgeslagen als een nieuwe feature, namelijk de \"quality_range\" feature. Aangezien het alleen de waardes 1 en 0 kan hebben, is het geschikt voor classificatie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low en High quality wine set (0 for low, 1 for high), set in label 'quality_range'\n",
    "bins = [0, 5, 10]\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "df_bins = df.copy()\n",
    "\n",
    "df_bins['quality_range'] = pd.cut(x=df_bins['quality'], bins=bins, labels=labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uitwerkingen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "Multiple Linear Regression is een statische methode die gebruikt wordt om de relatie tussen meerdere onafhankelijke variabelen en een afhankelijke variabele. Het is een verlenging van linear regression, waar maar een onafhankelijke variabele en maar een afhankelijke variabele aanwezig is. De relaties tussen de variabelen worden met behulp van een lineare formule. De formule heeft de volgende vorm:\n",
    "\n",
    "Y = b0 + b1X1 + b2X2 + ... + bn*Xn\n",
    "\n",
    "Waar Y de afhankelijke variabel is. X1, X2, ..., Xn zijn de onafhankelijke variabelen. b0, b1, b2, ...., bn zijn de coëfficiënten die gekoppeld zijn aan de variabelen. De coëfficiënten representeren de relatie tussen iedere onafhankelijke variabele en de afhankelijke variabele. \n",
    "\n",
    "#### Voorbeeld\n",
    "In het geval van onze code, wordt multiple linear regression toegepast op onze gevonden dataset. Hierbij is de feature \"quality\" de afhankelijke variabele en zijn de rest van de features de onafhankelijke variabelen. Hierdoor worden alle coëfficiënten berekend, waarmee de formule kan worden opgesteld.\n",
    "\n",
    "In de onderstaande code is te zien hoe allereerst de afhankelijke variabelen en onafhankelijke variabelen gesplitst worden. Daarnaast is te zien hoe er een train- en testdataset opgesteld wordt. \n",
    "\n",
    "Hierna is het zichtbaar hoe de multiple linear regression uitgewerkt wordt in Sklearn. Er wordt een model opgesteld wat getraind wordt met de traindata. Hierna kan gekeken worden naar hoe goed het model presteerd door verwachtingen uit te voeren over te testdata.\n",
    "\n",
    "Daarnaast worden hier de intercept en de coëfficiënten geprint die berekend zijn. Hiermee kan de formule opgesteld worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "y_lin = df['quality']\n",
    "X_lin = df.drop('quality',axis=1)\n",
    "\n",
    "X_lin_train, X_lin_test, y_lin_train, y_lin_test = train_test_split(X_lin, y_lin, test_size=0.1, random_state=40)\n",
    "\n",
    "#Sklearn solution\n",
    "model_lin = LinearRegression()\n",
    "\n",
    "model_lin.fit(X_lin_train, y_lin_train)\n",
    "\n",
    "predictions = model_lin.predict(X_lin_test)\n",
    "\n",
    "print(\"Intercept: \\n\", model_lin.intercept_)\n",
    "print(\"Coefficients: \\n\", model_lin.coef_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is ook een uitwerking gemaakt met behulp van statsmodel.api. Deze werd ook uitgewerkt omdat het mogelijk was om een duidelijker overzicht terug te geven van de coëfficiënten en intercept. Dit is gedaan om een duidelijker overzicht te krijgen over de betreffende coeëfficiënten en intercept per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SM (statsmodel.api) solution\n",
    "X_lin_train_sm = sm.add_constant(X_lin_train)\n",
    "\n",
    "model_sm = sm.OLS(y_lin_train, X_lin_train_sm).fit()\n",
    "predictions_sm = model_sm.predict(X_lin_train_sm)\n",
    "\n",
    "print_model = model_sm.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In het onderstaande stuk code wordt de R2-score, Mean Squared Error en Root Mean Squared Error berekend. De R2-score wordt berekent om aan te geven hoe goed het model presteert. Hoe dichter de R2-score bij 1 komt, hoe beter het model presteert. De Mean Squared Error en Root Mean Squared Error worden berekend om aan te geven hoe groot de afwijking is tussen de verwachte en de werkelijke waarde. Hoe lager deze waardes, hoe beter het model presteert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "y_lin_prediction = model_lin.predict(X_lin_test)\n",
    "\n",
    "lin_score = r2_score(y_lin_test, y_lin_prediction)\n",
    "\n",
    "print('R2 and Mean errors', '-'*35, \n",
    "      'R2-score   : {:.2f}'.format(lin_score), \n",
    "      'Mean Squared Error   : {:.2f}'.format(mean_squared_error(y_lin_test,y_lin_prediction)),\n",
    "      'Root Mean Squared Error   : {:.2f}'.format(np.sqrt(mean_squared_error(y_lin_test,y_lin_prediction))), sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe cross validation is uitgevoerd voor de Multiple Linear Regression. Er wordt gebruik gemaakt van K folds, waarbij de dataset in 10 splits wordt verdeeld. Hierbij wordt er 1 split gebruikt als testdata en de rest als traindata. Dit wordt 10 keer herhaald, waardoor er 10 verschillende scores worden berekend. Deze scores worden vervolgens gemiddeld, waardoor er een gemiddelde score wordt berekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Cross validation for Multiple Linear Regression\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cross_val_score_lin = cross_val_score(model_lin, X_lin, y_lin, scoring=\"r2\", cv=cv, n_jobs=1)\n",
    "print('R2 cross validation', '-'*35,\n",
    "\"Cross validation R2 scores:\", cross_val_score_lin,\n",
    "\"Cross validation mean R2 score:  :  {:.2f}\".format(cross_val_score_lin.mean()),sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic Regression is een methode voor binaire classificatie dat gebruikt maakt van een logistieke formule om de kans op een mogelijkheid te voorspellen. De Logistieke formule neemt een input van 1 of meerdere onafhankelijke variabelen en koppelt dit aan een getal tussen 0 en 1. Dit representeert de kans op deze waarde. De coëfficiënten van de onafhankelijke variabelen zijn opgehaald via trainingsdata. Het model wat hiermee is opgesteld wordt getraint om de optimale coëfficiënten te gebruiken om een binaire waarde te voorspellen. Zodra het model getraind is kan het gebruikt worden om voorspellingen over nieuwe data uit te voeren. \n",
    "\n",
    "De formule voor Logistic Regression heeft de volgende vorm:\n",
    "\n",
    "P = 1 / (1 + e^-(b0 + b1X1 + b2X2 + ... + bn*Xn))\n",
    "\n",
    "Waar P de kans is dat afhankelijke variabele 1 is. X1, X2, ..., Xn zijn de onafhankelijke variabelen. b0, b1, b2, ...., bn zijn de coëfficiënten die gekoppeld zijn aan de variabelen. De coëfficiënten representeren de relatie tussen iedere onafhankelijke variabele en de afhankelijke variabele. e is de wiskunde constante die ongeveer 2,718 is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voorbeeld\n",
    "In het geval van onze code, wordt logistic regression toegepast op onze gevonden dataset. Hierbij is de feature \"quality_range\" de afhankelijke variabele en zijn de rest van de features de onafhankelijke variabelen. Hierdoor worden alle coëfficiënten berekend, waarmee de formule kan worden opgesteld.\n",
    "\n",
    "Hieronder is te zien hoe de binaire afhankelijke variabele gesplitst wordt van de onafhankelijke variabelen. Daarnaast wordt hier de data opgesplitst in de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set X and y, also split into train and test sets\n",
    "X_log = df_bins[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']]\n",
    "\n",
    "y_log = df_bins['quality_range']\n",
    "\n",
    "X_log_train, X_log_test, y_log_train, y_log_test = train_test_split(X_log, y_log, test_size=0.1, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe de logistic regression wordt uitgevoerd met behulp van Sklearn. Hier wordt gelijk de accuraatheid bepaald met de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "model_lr = LogisticRegression(random_state=40, max_iter=1600)\n",
    "\n",
    "model_lr.fit(X_log_train, y_log_train)\n",
    "\n",
    "train_accuracy = model_lr.score(X_log_train, y_log_train)\n",
    "test_accuracy = model_lr.score(X_log_test, y_log_test)\n",
    "\n",
    "print('One-vs-rest', '-'*35, \n",
    "      'Accuracy in Train Group   : {:.2f}'.format(train_accuracy), \n",
    "      'Accuracy in Test  Group   : {:.2f}'.format(test_accuracy), sep='\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe cross validation is uitgevoerd voor de Logistic Regression. Er wordt gebruik gemaakt van K folds, waarbij de dataset in 10 splits wordt verdeeld. Hierbij wordt er 1 split gebruikt als testdata en de rest als traindata. Dit wordt 10 keer herhaald, waardoor er 10 verschillende scores worden berekend. Deze scores worden vervolgens gemiddeld, waardoor er een gemiddelde score wordt berekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation for Logistic Regression\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cross_val_score_lr = cross_val_score(model_lr, X_log, y_log, scoring=\"accuracy\", cv=cv, n_jobs=1)\n",
    "print('Accuracy cross validation', '-'*35,\n",
    "\"Cross validation accuracy scores:\", cross_val_score_lr,\n",
    "\"Cross validation mean accuracy score:  :  {:.2f}\".format(cross_val_score_lr.mean()),sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In het onderstaande stuk code is te zien hoe er een matrix wordt opgesteld om de accuraatheid van het model weer te geven. Hier is te zien hoe accuraat het model voorspeld en hoe het model voorspeld. Hier is te zien wat het model voorspelt tegenover de werkelijke waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_predictions = model_lr.predict(X_log_test)\n",
    "\n",
    "#confusion matrix\n",
    "score_lr = round(accuracy_score(y_log_test, log_predictions), 3)\n",
    "confusionMatrix_test = cm(y_log_test, log_predictions)\n",
    "sns.heatmap(confusionMatrix_test, annot=True, fmt='.0f')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score_lr), size = 15)\n",
    "plt.show()\n",
    "\n",
    "#Array confusion matrix\n",
    "log_pred_test = model_lr.predict(X_log_test)\n",
    "log_pred_train = model_lr.predict(X_log_train)\n",
    "\n",
    "cm = cm(y_log_test, log_pred_test)\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In het onderstaande stuk code wordt de ROC-curve berekend van de voorspellingen van het model. De ROC-curve geeft aan hoe accuraat het model voorspelt. Hoe dichter de curve bij de linkerbovenhoek ligt, hoe accurater het model voorspelt. Hoe dichter de curve bij de rechterbovenhoek ligt, hoe minder acuraat het model voorspelt. Dit doet het door de True Positive Rate (TPR) te vergelijken met de False Positive Rate (FPR). De TPR is de kans dat het model een positieve voorspelling doet en deze ook correct is. De FPR is de kans dat het model een positieve voorspelling doet en deze onjuist is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC-curve\n",
    "\n",
    "probs = model_lr.predict_proba(X_log_test)[:,1] #predict probabilities for the test data\n",
    "\n",
    "fpr, tpr, thresholds =  roc_curve(y_log_test, probs) #Get ROC Curve\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "#Plot ROC curve\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('1 - Specificity Score')\n",
    "plt.ylabel('Recall Score')\n",
    "plt.title('ROC-Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Decision Trees zijn een methode voor classificatie en regressie. Het is een methode die een beslissing neemt op basis van een aantal voorwaarden. Deze voorwaarden worden opgesteld door de data die gebruikt wordt om het model te trainen. Het model wordt getraint om de optimale voorwaarden te vinden om een beslissing te nemen. Zodra het model getraind is kan het gebruikt worden om voorspellingen over nieuwe data uit te voeren. Iedere node in de decision tree is een voorwaarde die de data moet voldoen om de volgende node te bereiken. De leaf nodes zijn de uiteindelijke beslissingen die het model neemt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voorbeeld Classificatie\n",
    "In het geval van onze code, wordt decision tree toegepast op onze gevonden dataset. Hierbij is de feature \"quality_range\" de afhankelijke variabele en zijn de rest van de features de onafhankelijke variabelen. Hierdoor worden alle voorwaarden berekend, waarmee de decision tree kan worden opgesteld.\n",
    "\n",
    "Hieronder is te zien hoe de binaire afhankelijke variabele gesplitst wordt van de onafhankelijke variabelen. Daarnaast wordt hier de data opgesplitst in de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X and y, also split into train and test sets\n",
    "X_tree_clas = df_bins[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "         'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "            'pH', 'sulphates', 'alcohol']]\n",
    "y_tree_clas = df_bins['quality_range']\n",
    "\n",
    "X_tree_clas_train, X_tree_clas_test, y_tree_clas_train, y_tree_clas_test = train_test_split(X_tree_clas, y_tree_clas, test_size=0.1, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe de decision tree voor classificatie wordt uitgevoerd met behulp van Sklearn. Hier wordt gelijk de accuraatheid berekend voor Gini index en entropy criteria met de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "model_tree_gini = DecisionTreeClassifier(random_state=40, criterion='gini')\n",
    "\n",
    "model_tree_entropy = DecisionTreeClassifier(random_state=40, criterion='entropy')\n",
    "\n",
    "model_tree_gini.fit(X_tree_clas_train, y_tree_clas_train)\n",
    "model_tree_entropy.fit(X_tree_clas_train, y_tree_clas_train)\n",
    "\n",
    "train_accuracy_gini = model_tree_gini.score(X_tree_clas_train, y_tree_clas_train)\n",
    "test_accuracy_gini = model_tree_gini.score(X_tree_clas_test, y_tree_clas_test)\n",
    "\n",
    "train_accuracy_entropy = model_tree_entropy.score(X_tree_clas_train, y_tree_clas_train)\n",
    "test_accuracy_entropy = model_tree_entropy.score(X_tree_clas_test, y_tree_clas_test)\n",
    "\n",
    "print('Decision Tree Gini Criteria vs Entropy Criteria', '-'*35,\n",
    "        'Accuracy in Test Gini Group   : {:.2f}'.format(test_accuracy_gini),\n",
    "        'Accuracy in Test Entropy Group   : {:.2f}'.format(test_accuracy_entropy), sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe cross validation is uitgevoerd voor de Decision Tree. Er wordt gebruik gemaakt van K folds, waarbij de dataset in 10 splits wordt verdeeld. Hierbij wordt er 1 split gebruikt als testdata en de rest als traindata. Dit wordt 10 keer herhaald, waardoor er 10 verschillende scores worden berekend. Deze scores worden vervolgens gemiddeld, waardoor er een gemiddelde score wordt berekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation for Decision Tree\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cross_val_score_tree_gini = cross_val_score(model_tree_gini, X_tree_clas, y_tree_clas, scoring=\"accuracy\", cv=cv, n_jobs=1)\n",
    "cross_val_score_tree_entropy = cross_val_score(model_tree_entropy, X_tree_clas, y_tree_clas, scoring=\"accuracy\", cv=cv, n_jobs=1)\n",
    "\n",
    "print('Accuracy cross validation', '-'*35,\n",
    "\"Cross validation accuracy scores gini:\", cross_val_score_tree_gini,\n",
    "\"Cross validation mean accuracy score gini:  :  {:.2f}\".format(cross_val_score_tree_gini.mean()),\n",
    "\"Cross validation accuracy scores entropy:\", cross_val_score_tree_entropy,\n",
    "\"Cross validation mean accuracy score entropy:  :  {:.2f}\".format(cross_val_score_tree_entropy.mean()),sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe een confusion matrix wordt opgesteld om de accuraatheid van het model weer te geven. Hier is te zien hoe accuraat het model voorspeld en hoe het model voorspeld. Hier is te zien wat het model voorspelt tegenover de werkelijke waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "#confusion matrix for Decision Tree Gini\n",
    "tree_gini_predictions = model_tree_gini.predict(X_tree_clas_test)\n",
    "\n",
    "score_tree_gini = round(accuracy_score(y_tree_clas_test, tree_gini_predictions), 3)\n",
    "tree_pred_test = model_tree_gini.predict(X_tree_clas_test)\n",
    "tree_pred_train = model_tree_gini.predict(X_tree_clas_train)\n",
    "\n",
    "cm_gini = cm(y_tree_clas_test, tree_pred_test)\n",
    "\n",
    "#Gini confusion matrix with sns heatmap\n",
    "sns.heatmap(cm_gini, annot=True, fmt='.0f')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score_tree_gini), size = 15)\n",
    "plt.show()\n",
    "\n",
    "#confusion matrix for Decision Tree Entropy with sns heatmap\n",
    "tree_entropy_predictions = model_tree_entropy.predict(X_tree_clas_test)\n",
    "\n",
    "score_tree_entropy = round(accuracy_score(y_tree_clas_test, tree_entropy_predictions), 3)\n",
    "tree_pred_test = model_tree_entropy.predict(X_tree_clas_test)\n",
    "tree_pred_train = model_tree_entropy.predict(X_tree_clas_train)\n",
    "\n",
    "cm_entropy = cm(y_tree_clas_test, tree_pred_test)\n",
    "\n",
    "#Entropy confusion matrix with sns heatmap\n",
    "sns.heatmap(cm_entropy, annot=True, fmt='.0f')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score_tree_entropy), size = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voorbeeld Regressie\n",
    "In het geval van onze code, wordt decision tree toegepast op onze gevonden dataset. Hierbij is de feature \"quality\" de afhankelijke variabele en zijn de rest van de features de onafhankelijke variabelen. Hierdoor worden alle voorwaarden berekend, waarmee de decision tree kan worden opgesteld.\n",
    "\n",
    "Hieronder is te zien hoe de afhankelijke variabele gesplitst wordt van de onafhankelijke variabelen. Daarnaast wordt hier de data opgesplitst in de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X and y, also split into train and test sets\n",
    "\n",
    "y_tree_reg = df['quality']\n",
    "X_tree_reg = df.drop('quality',axis=1)\n",
    "\n",
    "X_tree_reg_train, X_tree_reg_test, y_tree_reg_train, y_tree_reg_test = train_test_split(X_tree_reg, y_tree_reg, test_size=0.1, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe de decision tree voor regressie wordt uitgevoerd met behulp van Sklearn. Hier wordt gelijk de accuraatheid berekend met behulp van de r2-score met de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression\n",
    "model_tree_reg = DecisionTreeRegressor(random_state=40)\n",
    "\n",
    "model_tree_reg.fit(X_tree_reg_train, y_tree_reg_train)\n",
    "\n",
    "train_accuracy_tree_reg = model_tree_reg.score(X_tree_reg_train, y_tree_reg_train)\n",
    "test_accuracy_tree_reg = model_tree_reg.score(X_tree_reg_test, y_tree_reg_test)\n",
    "\n",
    "print('Decision Tree Regression', '-'*35,\n",
    "        'Accuracy in Train Group   : {:.2f}'.format(train_accuracy_tree_reg),\n",
    "        'Accuracy in Test Group   : {:.2f}'.format(test_accuracy_tree_reg), sep='\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe cross validation is uitgevoerd voor de Decision Tree. Er wordt gebruik gemaakt van K folds, waarbij de dataset in 10 splits wordt verdeeld. Hierbij wordt er 1 split gebruikt als testdata en de rest als traindata. Dit wordt 10 keer herhaald, waardoor er 10 verschillende scores worden berekend. Deze scores worden vervolgens gemiddeld, waardoor er een gemiddelde score wordt berekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation for Decision Tree Regression\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cross_val_score_tree_reg = cross_val_score(model_tree_reg, X_tree_reg, y_tree_reg, scoring=\"r2\", cv=cv, n_jobs=1)\n",
    "\n",
    "print('Accuracy cross validation', '-'*35,\n",
    "\"Cross validation accuracy scores:\", cross_val_score_tree_reg,\n",
    "\"Cross validation mean accuracy score:  :  {:.2f}\".format(cross_val_score_tree_reg.mean()),sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Random Forests is een methode voor classificatie en regression. Dit doet het door meerdere decision trees te combineren. Hierdoor wordt de voorspelling van het model verbeterd. De decision trees worden getraint op een random subset van de data. Hierdoor wordt voorkomen dat de decision trees te veel op elkaar lijken. Hierdoor wordt de voorspelling van het model verbeterd. De decision trees worden getraint op een random subset van de data. Hierdoor wordt voorkomen dat de decision trees te veel op elkaar lijken. Voor classificatie wordt de meest voorkomende beslissing genomen. Voor regression wordt de gemiddelde waarde van de beslissingen genomen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voorbeeld Classificatie\n",
    "In het geval van onze code, wordt random forest toegepast op onze gevonden dataset. Hierbij is de feature \"quality_range\" de afhankelijke variabele en zijn de rest van de features de onafhankelijke variabelen. Hierdoor worden alle voorwaarden berekend, waarmee de random forest kan worden opgesteld.\n",
    "\n",
    "Hieronder is te zien hoe de binaire afhankelijke variabele gesplitst wordt van de onafhankelijke variabelen. Daarnaast wordt hier de data opgesplitst in de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X and y, also split into train and test sets\n",
    "X_forest_clas = df_bins[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "            'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "            'pH', 'sulphates', 'alcohol']]\n",
    "y_forest_clas = df_bins['quality_range']\n",
    "\n",
    "X_forest_clas_train, X_forest_clas_test, y_forest_clas_train, y_forest_clas_test = train_test_split(X_forest_clas, y_forest_clas, test_size=0.1, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe de random forest wordt uitgevoerd met behulp van Sklearn. Hier wordt gelijk de accuraatheid berkend voor de Gini index en entropy criteria met de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "model_forest_gini = RandomForestClassifier(random_state=40, criterion='gini')\n",
    "\n",
    "model_forest_entropy = RandomForestClassifier(random_state=40, criterion='entropy')\n",
    "\n",
    "model_forest_gini.fit(X_forest_clas_train, y_forest_clas_train)\n",
    "model_forest_entropy.fit(X_forest_clas_train, y_forest_clas_train)\n",
    "\n",
    "train_accuracy_gini = model_forest_gini.score(X_forest_clas_train, y_forest_clas_train)\n",
    "test_accuracy_gini = model_forest_gini.score(X_forest_clas_test, y_forest_clas_test)\n",
    "\n",
    "train_accuracy_entropy = model_forest_entropy.score(X_forest_clas_train, y_forest_clas_train)\n",
    "test_accuracy_entropy = model_forest_entropy.score(X_forest_clas_test, y_forest_clas_test)\n",
    "\n",
    "print('Random Forest Gini Criteria vs Entropy Criteria', '-'*35,\n",
    "        'Accuracy in Test Gini Group   : {:.2f}'.format(test_accuracy_gini),\n",
    "        'Accuracy in Test Entropy Group   : {:.2f}'.format(test_accuracy_entropy), sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe cross validation is uitgevoerd voor de Random Forest. Er wordt gebruik gemaakt van K folds, waarbij de dataset in 10 splits wordt verdeeld. Hierbij wordt er 1 split gebruikt als testdata en de rest als traindata. Dit wordt 10 keer herhaald, waardoor er 10 verschillende scores worden berekend. Deze scores worden vervolgens gemiddeld, waardoor er een gemiddelde score wordt berekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation for Random Forest\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cross_val_score_forest_gini = cross_val_score(model_forest_gini, X_forest_clas, y_forest_clas, scoring=\"accuracy\", cv=cv, n_jobs=1)\n",
    "cross_val_score_forest_entropy = cross_val_score(model_forest_entropy, X_forest_clas, y_forest_clas, scoring=\"accuracy\", cv=cv, n_jobs=1)\n",
    "\n",
    "print('Accuracy cross validation', '-'*35,\n",
    "\"Cross validation accuracy scores gini:\", cross_val_score_forest_gini,\n",
    "\"Cross validation mean accuracy score gini:  :  {:.2f}\".format(cross_val_score_forest_gini.mean()),\n",
    "\"Cross validation accuracy scores entropy:\", cross_val_score_forest_entropy,\n",
    "\"Cross validation mean accuracy score entropy:  :  {:.2f}\".format(cross_val_score_forest_entropy.mean()),sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe een confusion matrix wordt opgesteld om de accuraatheid van het model weer te geven. Hier is te zien hoe accuraat het model voorspeld en hoe het model voorspeld. Hier is te zien wat het model voorspelt tegenover de werkelijke waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for Random Forest Gini\n",
    "forest_gini_predictions = model_forest_gini.predict(X_forest_clas_test)\n",
    "\n",
    "score_forest_gini = round(accuracy_score(y_forest_clas_test, forest_gini_predictions), 3)\n",
    "\n",
    "forest_pred_test = model_forest_gini.predict(X_forest_clas_test)\n",
    "forest_pred_train = model_forest_gini.predict(X_forest_clas_train)\n",
    "\n",
    "cm_gini = cm(y_forest_clas_test, forest_pred_test)\n",
    "\n",
    "#Gini confusion matrix with sns heatmap\n",
    "sns.heatmap(cm_gini, annot=True, fmt='.0f')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score_forest_gini), size = 15)\n",
    "plt.show()\n",
    "\n",
    "#confusion matrix for Random Forest Entropy with sns heatmap\n",
    "forest_entropy_predictions = model_forest_entropy.predict(X_forest_clas_test)\n",
    "\n",
    "score_forest_entropy = round(accuracy_score(y_forest_clas_test, forest_entropy_predictions), 3)\n",
    "\n",
    "forest_pred_test = model_forest_entropy.predict(X_forest_clas_test)\n",
    "forest_pred_train = model_forest_entropy.predict(X_forest_clas_train)\n",
    "\n",
    "cm_entropy = cm(y_forest_clas_test, forest_pred_test)\n",
    "\n",
    "#Entropy confusion matrix with sns heatmap\n",
    "sns.heatmap(cm_entropy, annot=True, fmt='.0f')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score_forest_entropy), size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voorbeeld Regressie\n",
    "In het geval van onze code, wordt random forest toegepast op onze gevonden dataset. Hierbij is de feature \"quality\" de afhankelijke variabele en zijn de rest van de features de onafhankelijke variabelen. Hierdoor worden alle voorwaarden berekend, waarmee de random forest kan worden opgesteld.\n",
    "\n",
    "Hieronder is te zien hoe de afhankelijke variabele gesplitst wordt van de onafhankelijke variabelen. Daarnaast wordt hier de data opgesplitst in de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X and y, also split into train and test sets\n",
    "\n",
    "y_forest_reg = df['quality']\n",
    "X_forest_reg = df.drop('quality',axis=1)\n",
    "\n",
    "X_forest_reg_train, X_forest_reg_test, y_forest_reg_train, y_forest_reg_test = train_test_split(X_forest_reg, y_forest_reg, test_size=0.1, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe de random forest wordt uitgevoerd met behulp van Sklearn. Hier wordt gelijk de accuraatheid berkend met behulp van de r2-score met de train- en testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "model_forest_reg = RandomForestRegressor(random_state=40)\n",
    "\n",
    "model_forest_reg.fit(X_forest_reg_train, y_forest_reg_train)\n",
    "\n",
    "train_accuracy_forest_reg = model_forest_reg.score(X_forest_reg_train, y_forest_reg_train)\n",
    "test_accuracy_forest_reg = model_forest_reg.score(X_forest_reg_test, y_forest_reg_test)\n",
    "\n",
    "print('Random Forest Regression', '-'*35,\n",
    "        'Accuracy in Train Group   : {:.2f}'.format(train_accuracy_forest_reg),\n",
    "        'Accuracy in Test Group   : {:.2f}'.format(test_accuracy_forest_reg), sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder is te zien hoe cross validation is uitgevoerd voor de Random Forest. Er wordt gebruik gemaakt van K folds, waarbij de dataset in 10 splits wordt verdeeld. Hierbij wordt er 1 split gebruikt als testdata en de rest als traindata. Dit wordt 10 keer herhaald, waardoor er 10 verschillende scores worden berekend. Deze scores worden vervolgens gemiddeld, waardoor er een gemiddelde score wordt berekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation for Random Forest Regression\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cross_val_score_forest_reg = cross_val_score(model_forest_reg, X_forest_reg, y_forest_reg, scoring=\"r2\", cv=cv, n_jobs=1)\n",
    "\n",
    "print('Accuracy cross validation', '-'*35,\n",
    "\"Cross validation accuracy scores:\", cross_val_score_forest_reg,\n",
    "\"Cross validation mean accuracy score:  :  {:.2f}\".format(cross_val_score_forest_reg.mean()),sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie\n",
    "### Multiple Linear Regression vs Logistic Regression\n",
    "Logistic regression bleek uit deze opdracht accurater te zijn in het voorspellen van de kwaliteit van de rode wijnen. Dit komt doordat de kwaliteit van wijnen een balans van meerdere aspecten is. Het toevoegen of verminderen van een bepaald aspect betekend niet altijd dat de kwaliteit lineair veranderd. Dit is terug te zijn in de accuraatheidscores in beide modellen. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree vs Random Forest Classificatie\n",
    "Random Forest bleek uit deze opdracht accurater te zijn in het voorspellen van de kwaliteit van de rode wijnen. Dit komt doordat Random Forests meerdere decision trees combineert. Hierdoor wordt de voorspelling van het model verbeterd. De decision trees worden getraint op een random subset van de data, om te voorkomen dat de decision trees te veel op elkaar lijken. Als gevolg hiervan worden de voorspellingen van het model verbeterd."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree vs Random Forest Regressie\n",
    "Random Forest bleek uit deze opdracht veel accurater te zijn in het voorspellen van de kwaliteit van de rode wijnen. Dit komt doordat Random Forests meerdere decision trees combineert. Hierdoor wordt de voorspelling van het model verbeterd. Dit is vooral belangrijk in de regressie omdat het resultaat hiervan geen binaire waarde is. Het is dus ook belangrijk dat de voorspellingen van het model zo nauwkeurig mogelijk zijn. Dit is bij Random Forests beter terug te zien dan bij Decision Trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov  4 2022, 13:42:51) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d045bd1c9f21cbd324c3fee8810b32877d8b73fac13db8029883140816c6d6fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
